{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Revenue from Parking Citations in Baltimore\n",
    "Capstone Project for Springboard Data Science Bootcamp\n",
    "\n",
    "Tamara Monge\n",
    "\n",
    "### Section 4: Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "# analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "from time import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# supervised learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score   \n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing all ones (all citations were paid) results in a  67.0 % success rate.\n",
      "Can models do better?\n"
     ]
    }
   ],
   "source": [
    "# Import prepared feature array\n",
    "X = pd.read_csv('persistence/features_2018-05-25.csv') #('persistence/features_2018-05-22.csv')\n",
    "X.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "# Import prepared target vector\n",
    "y = pd.read_csv('persistence/target_2018-05-22.csv', header=None).iloc[:,1]\n",
    "\n",
    "print('Guessing all ones (all citations were paid) results in a ', round(100*y.sum()/y.count()),'% success rate.')\n",
    "print('Can models do better?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We must first normalize the data and split it into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize/scale data\n",
    "Xscaled = scale(X)\n",
    "\n",
    "# Split data into training and test sets (70% and 30% of the full dataset).\n",
    "Xtraining, Xtest, ytraining, ytest = train_test_split(Xscaled, y, train_size=0.7, random_state=42)\n",
    "\n",
    "# Split training set again, into train and evaluation sets (70% and 30% of the training set)\n",
    "Xtrain, Xeval, ytrain, yeval = train_test_split(Xtraining, ytraining, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by building a dummy classifier that predicts using only the `fine` feature, which we can use as a benchmark for the other classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import prepared dummy feature array (contains only `fine`)\n",
    "F = pd.read_csv('persistence/fine_2018-05-25.csv', header=None).iloc[:,1:2]\n",
    "\n",
    "# Scale it \n",
    "Fscaled = scale(F)\n",
    "\n",
    "# Split it\n",
    "F_Xtraining, F_Xtest, F_ytraining, F_ytest = train_test_split(Fscaled, y, train_size=0.7, random_state=42)\n",
    "\n",
    "# Split it again, same logic as cell above. \n",
    "F_Xtrain, F_Xeval, F_ytrain, F_yeval = train_test_split(F_Xtraining, F_ytraining, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=42, strategy='stratified')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier\n",
      "=====================\n",
      "Accuracy: 0.557796048107\n",
      "Precision: 0.669984546859\n",
      "Recall: 0.671625300423\n",
      "F1: 0.670803920342\n"
     ]
    }
   ],
   "source": [
    "# Build dummy classifier\n",
    "dummy = DummyClassifier(random_state=42) \n",
    "\n",
    "# Train \n",
    "dummy.fit(F_Xtrain, F_ytrain)\n",
    "\n",
    "# Predict\n",
    "ypred_dummy = dummy.predict(F_Xeval)\n",
    "\n",
    "# Performance Metrics\n",
    "print('Dummy Classifier')\n",
    "print('=====================')\n",
    "print('Accuracy:',accuracy_score(F_yeval, ypred_dummy))\n",
    "print('Precision:',precision_score(F_yeval, ypred_dummy))\n",
    "print('Recall:', recall_score(F_yeval, ypred_dummy))\n",
    "print('F1:', f1_score(F_yeval, ypred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the dummy classifier predicts with 56% accuracy, which is worse than the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to more complex classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train gridsearchCV estimator from scratch ####\n",
    "# # Range of parameters to gridsearch\n",
    "# logreg_params = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# # Build GridSearch Cross Validation estimator to find best hyperparameters\n",
    "# logreg_gridsearch = GridSearchCV(LogisticRegression(), logreg_params, cv=5, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# # Train estimator\n",
    "# start = time()\n",
    "# logreg_gridsearch.fit(Xtrain, ytrain)  \n",
    "# print('Training took ', time()-start, 'seconds.')\n",
    "\n",
    "# # Save the trained estimator \n",
    "# filename = 'persistence/logreg_gridsearch_' + str(date.today()) + '.sav'\n",
    "# joblib.dump(logreg_gridsearch, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to load trained gridsearch estimator from disk ####\n",
    "# filename = 'persistence/logreg_gridsearch_2018-05-25.sav'\n",
    "# logreg_gridsearch = joblib.load(filename)\n",
    "# print('Best parameters:',logreg_gridsearch.best_params_)\n",
    "# print('Best score:', logreg_gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train Logistic Regression estimator with best hyperparameter, so can evaluate performance metrics ####\n",
    "# Build Logistic Regression estimator\n",
    "# logreg = LogisticRegression(C=1)\n",
    "\n",
    "# # Train estimator\n",
    "# logreg.fit(Xtrain, ytrain)\n",
    "\n",
    "# # Save trained estimator\n",
    "# filename = 'persistence/logreg_' + str(date.today()) + '.sav'\n",
    "# joblib.dump(logreg, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "====================\n",
      "Accuracy: 0.748231123065\n",
      "Precision: 0.788936304726\n",
      "Recall: 0.852847037919\n",
      "F1: 0.81964772466\n"
     ]
    }
   ],
   "source": [
    "#### Uncomment this cell to load trained Logistic Regression estimator from disk ####\n",
    "filename = 'persistence/logreg_2018-05-31.sav'\n",
    "logreg = joblib.load(filename)\n",
    "\n",
    "# Predict on eval set\n",
    "ypred_logreg = logreg.predict(Xeval)\n",
    "\n",
    "# Performance Metrics\n",
    "print('Logistic Regression')\n",
    "print('====================')\n",
    "print('Accuracy:',accuracy_score(yeval, ypred_logreg))\n",
    "print('Precision:',precision_score(yeval, ypred_logreg))\n",
    "print('Recall:', recall_score(yeval, ypred_logreg))\n",
    "print('F1:', f1_score(yeval, ypred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train gridsearchCV estimator from scratch ####\n",
    "# lsvc_params =  {\"C\":[0.01, 0.1, 1, 10, 100]}\n",
    "# lsvc_gridsearch = GridSearchCV(LinearSVC(), lsvc_params, n_jobs=4, cv=5, scoring=make_scorer(accuracy_score))\n",
    "# start = time()\n",
    "# lsvc_gridsearch.fit(Xtrain, ytrain)  \n",
    "# print('Training took ', time()-start, 'seconds.')\n",
    "\n",
    "# # Save the trained model \n",
    "# filename = 'persistence/lsvc_gridsearch_'+ str(date.today()) + '.sav'\n",
    "# joblib.dump(lsvc_gridsearch, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to load trained gridsearch estimator from disk ####\n",
    "# filename = 'persistence/lsvc_gridsearch_2018-05-13.sav'\n",
    "# lsvc_gridsearch = joblib.load(filename)\n",
    "# print('Best parameters:', lsvc_gridsearch.best_params_)\n",
    "# print('Best score:', lsvc_gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train Linear SVC estimator with best hyperparameter, so can evaluate performance metrics ####\n",
    "# Build Linear SVC estimator\n",
    "# lsvc = LinearSVC(C=0.1)\n",
    "\n",
    "# # Train estimator\n",
    "# lsvc.fit(Xtrain, ytrain)\n",
    "\n",
    "# # Save trained estimator\n",
    "# filename = 'persistence/lsvc_' + str(date.today()) + '.sav'\n",
    "# joblib.dump(lsvc, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC\n",
      "============\n",
      "Accuracy: 0.745610281645\n",
      "Precision: 0.786552536384\n",
      "Recall: 0.851981365257\n",
      "F1: 0.817960620923\n"
     ]
    }
   ],
   "source": [
    "#### Uncomment this cell to load trained Linear SVC estimator from disk ####\n",
    "filename = 'persistence/lsvc_2018-05-31.sav'\n",
    "lsvc = joblib.load(filename)\n",
    "\n",
    "# Predict on eval set\n",
    "ypred_lsvc = lsvc.predict(Xeval)\n",
    "\n",
    "# Performance Metrics\n",
    "print('Linear SVC')\n",
    "print('============')\n",
    "print('Accuracy:',accuracy_score(yeval, ypred_lsvc))\n",
    "print('Precision:',precision_score(yeval, ypred_lsvc))\n",
    "print('Recall:', recall_score(yeval, ypred_lsvc))\n",
    "print('F1:', f1_score(yeval, ypred_lsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) SVC with RBF Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the RBF-SVC on the entire feature array is untennable (didn't finish in 14 days). \n",
    "To work around this, let's select a manageable number (20-30) of the most important features based on the coefficients returned from the logistic regression classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.720146</td>\n",
       "      <td>desc_ALL OTHER PARKING METER VIOLATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.513078</td>\n",
       "      <td>desc_NO STOPPING/STANDING NOT TOW-AWAY ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.452920</td>\n",
       "      <td>desc_FIXED SPEED CAMERA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.444737</td>\n",
       "      <td>desc_NO STOPPING/STANDING TOW AWAY ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.439693</td>\n",
       "      <td>desc_RESIDENTIAL PARKING PERMIT ONLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.406354</td>\n",
       "      <td>desc_NO STOP/PARK STREET CLEANING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.284872</td>\n",
       "      <td>desc_ALL OTHER STOPPING OR PARKING VIOLATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.229094</td>\n",
       "      <td>desc_OBSTRUCT/IMPEDING MOVEMENT OF PEDESTRIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.218887</td>\n",
       "      <td>desc_IN TRANSIT ZONE/STOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.215252</td>\n",
       "      <td>instate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.179953</td>\n",
       "      <td>desc_PASSENGER LOADING ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.175212</td>\n",
       "      <td>desc_NO STOPPING//PARKING STADIUM EVENT CAMDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.164994</td>\n",
       "      <td>desc_NO STOP/PARK HANDICAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.163044</td>\n",
       "      <td>quad_SOUTHEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.162749</td>\n",
       "      <td>desc_LESS THAN 15 FEET FROM FIRE HYDRANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.119293</td>\n",
       "      <td>desc_EXPIRED TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.097100</td>\n",
       "      <td>make_TOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.091201</td>\n",
       "      <td>make_UPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.087252</td>\n",
       "      <td>desc_COMMERCIAL VEH/RESIDENCE UNDER 20,000 LBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.083375</td>\n",
       "      <td>desc_OBSTRUCT/IMPEDING FLOW OF TRAFFIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.078633</td>\n",
       "      <td>make_SUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.070606</td>\n",
       "      <td>quad_SOUTHWEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.069659</td>\n",
       "      <td>desc_EXCEEDING 48 HOURS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.065743</td>\n",
       "      <td>quad_NORTHWEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.050409</td>\n",
       "      <td>make_TRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.049824</td>\n",
       "      <td>desc_BLOCKING GARAGE OR DRIVEWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.046015</td>\n",
       "      <td>make_VPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.042030</td>\n",
       "      <td>make_MAZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.041711</td>\n",
       "      <td>desc_FIRE LANE/HANDICAPPED VIOLATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.037976</td>\n",
       "      <td>desc_COMMERCIAL VEH/RESIDENCE OVER 20,000 LBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-0.037064</td>\n",
       "      <td>hr_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.039099</td>\n",
       "      <td>mo_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-0.041101</td>\n",
       "      <td>make_OLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-0.041690</td>\n",
       "      <td>hr_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>-0.042605</td>\n",
       "      <td>hr_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-0.042673</td>\n",
       "      <td>make_INF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>-0.043007</td>\n",
       "      <td>day_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-0.043672</td>\n",
       "      <td>make_LIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.046311</td>\n",
       "      <td>make_BUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>-0.046877</td>\n",
       "      <td>hr_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-0.048694</td>\n",
       "      <td>make_PON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.053237</td>\n",
       "      <td>mo_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.053259</td>\n",
       "      <td>make_CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.054512</td>\n",
       "      <td>make_MER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.066142</td>\n",
       "      <td>make_DOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.073885</td>\n",
       "      <td>make_ACU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.074203</td>\n",
       "      <td>make_CHR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-0.101650</td>\n",
       "      <td>mo_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.120727</td>\n",
       "      <td>mo_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.129364</td>\n",
       "      <td>fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.151273</td>\n",
       "      <td>mo_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.164091</td>\n",
       "      <td>make_TRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.187875</td>\n",
       "      <td>mo_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-0.307119</td>\n",
       "      <td>mo_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.389402</td>\n",
       "      <td>mo_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.398328</td>\n",
       "      <td>yr_2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.416261</td>\n",
       "      <td>mo_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.422876</td>\n",
       "      <td>mo_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.626832</td>\n",
       "      <td>mo_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-1.092708</td>\n",
       "      <td>yr_2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficients                                        features\n",
       "318      0.720146         desc_ALL OTHER PARKING METER VIOLATIONS\n",
       "336      0.513078     desc_NO STOPPING/STANDING NOT TOW-AWAY ZONE\n",
       "326      0.452920                         desc_FIXED SPEED CAMERA\n",
       "337      0.444737         desc_NO STOPPING/STANDING TOW AWAY ZONE\n",
       "341      0.439693            desc_RESIDENTIAL PARKING PERMIT ONLY\n",
       "332      0.406354               desc_NO STOP/PARK STREET CLEANING\n",
       "319      0.284872   desc_ALL OTHER STOPPING OR PARKING VIOLATIONS\n",
       "339      0.229094   desc_OBSTRUCT/IMPEDING MOVEMENT OF PEDESTRIAN\n",
       "328      0.218887                       desc_IN TRANSIT ZONE/STOP\n",
       "1        0.215252                                         instate\n",
       "340      0.179953                     desc_PASSENGER LOADING ZONE\n",
       "335      0.175212  desc_NO STOPPING//PARKING STADIUM EVENT CAMDEN\n",
       "331      0.164994                      desc_NO STOP/PARK HANDICAP\n",
       "410      0.163044                                  quad_SOUTHEAST\n",
       "330      0.162749        desc_LESS THAN 15 FEET FROM FIRE HYDRANT\n",
       "324      0.119293                               desc_EXPIRED TAGS\n",
       "280      0.097100                                        make_TOY\n",
       "293      0.091201                                        make_UPS\n",
       "322      0.087252  desc_COMMERCIAL VEH/RESIDENCE UNDER 20,000 LBS\n",
       "338      0.083375          desc_OBSTRUCT/IMPEDING FLOW OF TRAFFIC\n",
       "262      0.078633                                        make_SUB\n",
       "411      0.070606                                  quad_SOUTHWEST\n",
       "323      0.069659                         desc_EXCEEDING 48 HOURS\n",
       "409      0.065743                                  quad_NORTHWEST\n",
       "284      0.050409                                        make_TRU\n",
       "320      0.049824                desc_BLOCKING GARAGE OR DRIVEWAY\n",
       "306      0.046015                                        make_VPG\n",
       "178      0.042030                                        make_MAZ\n",
       "325      0.041711            desc_FIRE LANE/HANDICAPPED VIOLATION\n",
       "321      0.037976   desc_COMMERCIAL VEH/RESIDENCE OVER 20,000 LBS\n",
       "..            ...                                             ...\n",
       "397     -0.037064                                           hr_12\n",
       "345     -0.039099                                            mo_2\n",
       "210     -0.041101                                        make_OLD\n",
       "395     -0.041690                                           hr_10\n",
       "393     -0.042605                                            hr_8\n",
       "141     -0.042673                                        make_INF\n",
       "384     -0.043007                                          day_30\n",
       "168     -0.043672                                        make_LIN\n",
       "55      -0.046311                                        make_BUI\n",
       "394     -0.046877                                            hr_9\n",
       "222     -0.048694                                        make_PON\n",
       "346     -0.053237                                            mo_3\n",
       "59      -0.053259                                        make_CAD\n",
       "187     -0.054512                                        make_MER\n",
       "87      -0.066142                                        make_DOD\n",
       "31      -0.073885                                        make_ACU\n",
       "68      -0.074203                                        make_CHR\n",
       "347     -0.101650                                            mo_4\n",
       "348     -0.120727                                            mo_5\n",
       "0       -0.129364                                            fine\n",
       "349     -0.151273                                            mo_6\n",
       "281     -0.164091                                        make_TRA\n",
       "350     -0.187875                                            mo_7\n",
       "355     -0.307119                                           mo_12\n",
       "351     -0.389402                                            mo_8\n",
       "343     -0.398328                                         yr_2016\n",
       "353     -0.416261                                           mo_10\n",
       "352     -0.422876                                            mo_9\n",
       "354     -0.626832                                           mo_11\n",
       "344     -1.092708                                         yr_2017\n",
       "\n",
       "[412 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the Logistic Regression coefficients in a dataframe\n",
    "df_features = pd.DataFrame({'features':np.array(X.columns), 'coefficients':logreg.coef_[0,:]})\n",
    "df_features.sort_values('coefficients', ascending=False)\n",
    "\n",
    "# Determine which threshold to use to get a manageable number of features (20-30)\n",
    "(abs(df_features.coefficients) >= 0.5).sum()\n",
    "(abs(df_features.coefficients) >= 0.2).sum()\n",
    "(abs(df_features.coefficients) >= 0.1).sum()\n",
    "(abs(df_features.coefficients) >= 0.07).sum()\n",
    "(abs(df_features.coefficients) >= 0.05).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like a threshold of >= 0.1 will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.129364</td>\n",
       "      <td>fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.215252</td>\n",
       "      <td>instate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.164091</td>\n",
       "      <td>make_TRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.720146</td>\n",
       "      <td>desc_ALL OTHER PARKING METER VIOLATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.284872</td>\n",
       "      <td>desc_ALL OTHER STOPPING OR PARKING VIOLATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.119293</td>\n",
       "      <td>desc_EXPIRED TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.452920</td>\n",
       "      <td>desc_FIXED SPEED CAMERA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.218887</td>\n",
       "      <td>desc_IN TRANSIT ZONE/STOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.162749</td>\n",
       "      <td>desc_LESS THAN 15 FEET FROM FIRE HYDRANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.164994</td>\n",
       "      <td>desc_NO STOP/PARK HANDICAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.406354</td>\n",
       "      <td>desc_NO STOP/PARK STREET CLEANING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.175212</td>\n",
       "      <td>desc_NO STOPPING//PARKING STADIUM EVENT CAMDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.513078</td>\n",
       "      <td>desc_NO STOPPING/STANDING NOT TOW-AWAY ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.444737</td>\n",
       "      <td>desc_NO STOPPING/STANDING TOW AWAY ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.229094</td>\n",
       "      <td>desc_OBSTRUCT/IMPEDING MOVEMENT OF PEDESTRIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.179953</td>\n",
       "      <td>desc_PASSENGER LOADING ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.439693</td>\n",
       "      <td>desc_RESIDENTIAL PARKING PERMIT ONLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.398328</td>\n",
       "      <td>yr_2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-1.092708</td>\n",
       "      <td>yr_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-0.101650</td>\n",
       "      <td>mo_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.120727</td>\n",
       "      <td>mo_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.151273</td>\n",
       "      <td>mo_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.187875</td>\n",
       "      <td>mo_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.389402</td>\n",
       "      <td>mo_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.422876</td>\n",
       "      <td>mo_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.416261</td>\n",
       "      <td>mo_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.626832</td>\n",
       "      <td>mo_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-0.307119</td>\n",
       "      <td>mo_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.163044</td>\n",
       "      <td>quad_SOUTHEAST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficients                                        features\n",
       "0       -0.129364                                            fine\n",
       "1        0.215252                                         instate\n",
       "281     -0.164091                                        make_TRA\n",
       "318      0.720146         desc_ALL OTHER PARKING METER VIOLATIONS\n",
       "319      0.284872   desc_ALL OTHER STOPPING OR PARKING VIOLATIONS\n",
       "324      0.119293                               desc_EXPIRED TAGS\n",
       "326      0.452920                         desc_FIXED SPEED CAMERA\n",
       "328      0.218887                       desc_IN TRANSIT ZONE/STOP\n",
       "330      0.162749        desc_LESS THAN 15 FEET FROM FIRE HYDRANT\n",
       "331      0.164994                      desc_NO STOP/PARK HANDICAP\n",
       "332      0.406354               desc_NO STOP/PARK STREET CLEANING\n",
       "335      0.175212  desc_NO STOPPING//PARKING STADIUM EVENT CAMDEN\n",
       "336      0.513078     desc_NO STOPPING/STANDING NOT TOW-AWAY ZONE\n",
       "337      0.444737         desc_NO STOPPING/STANDING TOW AWAY ZONE\n",
       "339      0.229094   desc_OBSTRUCT/IMPEDING MOVEMENT OF PEDESTRIAN\n",
       "340      0.179953                     desc_PASSENGER LOADING ZONE\n",
       "341      0.439693            desc_RESIDENTIAL PARKING PERMIT ONLY\n",
       "343     -0.398328                                         yr_2016\n",
       "344     -1.092708                                         yr_2017\n",
       "347     -0.101650                                            mo_4\n",
       "348     -0.120727                                            mo_5\n",
       "349     -0.151273                                            mo_6\n",
       "350     -0.187875                                            mo_7\n",
       "351     -0.389402                                            mo_8\n",
       "352     -0.422876                                            mo_9\n",
       "353     -0.416261                                           mo_10\n",
       "354     -0.626832                                           mo_11\n",
       "355     -0.307119                                           mo_12\n",
       "410      0.163044                                  quad_SOUTHEAST"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(623208, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the top 29 features from LogReg \n",
    "df_select29 = df_features[abs(df_features.coefficients) >= 0.1] \n",
    "df_select29\n",
    "\n",
    "# Extract only the 29 identified features\n",
    "X29 = X[df_select29.features]\n",
    "X29.shape\n",
    "\n",
    "# Normalize/scale \n",
    "X29scaled = scale(X29)\n",
    "\n",
    "# Split data for training and testing (70%, 30% of full set respectively)\n",
    "X29training, X29test, y29training, y29test = train_test_split(X29scaled, y, train_size=0.7, random_state=42)\n",
    "\n",
    "## Split training set again into train and eval (70%, 30% of training set)\n",
    "X29train, X29eval, y29train, y29eval = train_test_split(X29training, y29training, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the pared-down feature array, let's train the svc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train gridsearchCV estimator from scratch ####\n",
    "# svc_params =  {\"C\":[0.01, 0.1, 1, 10, 100], \"gamma\":[0.25, 0.5, 0.75]}\n",
    "# svc29_gridsearch = GridSearchCV(SVC(), svc_params, n_jobs=4, cv=5, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "# # Train\n",
    "# start = time()\n",
    "# svc29.fit(X29train, y29train)\n",
    "# print(time()-start)\n",
    "# print('Training took ', time()-start, 'seconds.')\n",
    "\n",
    "# # Save the trained estimator \n",
    "# filename = 'persistence/svc29_gridsearch_'+ str(date.today()) + '.sav'\n",
    "# joblib.dump(svc29_gridsearch, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to load trained gridsearch estimator from disk ####\n",
    "# filename = 'persistence/svc29_gridsearch_2018-05-17.sav'\n",
    "# svc29_gridsearch = joblib.load(filename)\n",
    "# print('Best parameters:', svc29_gridsearch.best_params_)\n",
    "# print('Best score:', svc29_gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train RBF SVC estimator with best hyperparameter, so can evaluate performance metrics ####\n",
    "# # Build\n",
    "# svc29 = SVC(C=1, gamma=0.25)\n",
    "\n",
    "# # Train\n",
    "# svc29.fit(X29train, y29train)\n",
    "\n",
    "# # Save trained estimator\n",
    "# filename = 'persistence/svc29_' + str(date.today()) + '.sav'\n",
    "# joblib.dump(svc29, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVC\n",
      "===========\n",
      "Accuracy: 0.752028668796\n",
      "Precision: 0.795083715474\n",
      "Recall: 0.849213490825\n",
      "F1: 0.821257635091\n"
     ]
    }
   ],
   "source": [
    "#### Uncomment this cell to load trained RBF SVC estimator from disk ####\n",
    "filename = 'persistence/svc29_2018-06-01.sav'\n",
    "svc29 = joblib.load(filename)\n",
    "\n",
    "# Predict on eval set\n",
    "ypred_svc29 = svc29.predict(X29eval)\n",
    "\n",
    "# Performance Metrics\n",
    "print('RBF SVC')\n",
    "print('===========')\n",
    "print('Accuracy:',accuracy_score(y29eval, ypred_svc29))\n",
    "print('Precision:',precision_score(y29eval, ypred_svc29))\n",
    "print('Recall:', recall_score(y29eval, ypred_svc29))\n",
    "print('F1:', f1_score(y29eval, ypred_svc29))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  D) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train gridsearchCV estimator from scratch ####\n",
    "# dtc_params =  {\"max_depth\":[5, 10, 30, 50, 100]}\n",
    "# dtc_gridsearch = GridSearchCV(DecisionTreeClassifier(), dtc_params, n_jobs=4, cv=5, scoring=make_scorer(accuracy_score))\n",
    "# start = time()\n",
    "# dtc_gridsearch.fit(Xtrain, ytrain)  \n",
    "# print('Training took ', time()-start, 'seconds.')\n",
    "\n",
    "# # Save the trained estimator \n",
    "# filename = 'persistence/dtc_gridsearch_'+ str(date.today()) + '.sav'\n",
    "# joblib.dump(dtc_gridsearch, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # #### Uncomment this cell to load trained gridsearch estimator from disk ####\n",
    "# filename = 'persistence/dtc_gridsearch_2018-05-20.sav'\n",
    "# dtc_gridsearch = joblib.load(filename)\n",
    "# print('Best parameters:', dtc_gridsearch.best_params_)\n",
    "# print('Best score:', dtc_gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train Decision Tree estimator with best hyperparameter, so can evaluate performance metrics ####\n",
    "# # Build\n",
    "# dtc = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "# # Train\n",
    "# dtc.fit(Xtrain, ytrain)\n",
    "\n",
    "# # Save trained estimator\n",
    "# filename = 'persistence/dtc_' + str(date.today()) + '.sav'\n",
    "# joblib.dump(dtc, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "==============\n",
      "Accuracy: 0.754886379266\n",
      "Precision: 0.773924244808\n",
      "Recall: 0.896483774333\n",
      "F1: 0.830707851115\n"
     ]
    }
   ],
   "source": [
    "#### Uncomment this cell to load trained Decision Tree estimator from disk ####\n",
    "filename = 'persistence/dtc_2018-05-31.sav'\n",
    "dtc = joblib.load(filename)\n",
    "\n",
    "# Predict on eval set\n",
    "ypred_dtc = dtc.predict(Xeval)\n",
    "\n",
    "# Performance Metrics\n",
    "print('Decision Tree')\n",
    "print('==============')\n",
    "print('Accuracy:',accuracy_score(yeval, ypred_dtc))\n",
    "print('Precision:',precision_score(yeval, ypred_dtc))\n",
    "print('Recall:', recall_score(yeval, ypred_dtc))\n",
    "print('F1:', f1_score(yeval, ypred_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train gridsearchCV estimator from scratch ####\n",
    "# rfc_params =  {\"max_depth\":[5, 10, 30, 50, 100], \"n_estimators\":[5, 10, 25, 50], \"min_samples_leaf\":[1, 2, 4, 7, 10]}\n",
    "# rfc_gridsearch = GridSearchCV(RandomForestClassifier(random_state=42), rfc_params, n_jobs=4, cv=5, scoring=make_scorer(accuracy_score))\n",
    "# start = time()\n",
    "# rfc_gridsearch.fit(Xtrain, ytrain)  \n",
    "# print('Training took ', time()-start, 'seconds.')\n",
    "\n",
    "# # Save the trained estimator\n",
    "# filename = 'persistence/rfc_gridsearch_'+ str(date.today()) + '.sav'\n",
    "# joblib.dump(rfc_gridsearch, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # #### Uncomment this cell to load trained gridsearch estimator from disk ####\n",
    "# filename = 'persistence/rfc_gridsearch_2018-05-20.sav'\n",
    "# rfc_gridsearch = joblib.load(filename)\n",
    "# print('Best parameters:', rfc_gridsearch.best_params_)\n",
    "# print('Best score:', rfc_gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train Decision Tree estimator with best hyperparameter, so can evaluate performance metrics ####\n",
    "# Build\n",
    "# rfc = RandomForestClassifier(random_state=42, max_depth=100, min_samples_leaf=2, n_estimators=50)\n",
    "\n",
    "# # Train\n",
    "# rfc.fit(Xtrain, ytrain)\n",
    "\n",
    "# # Save trained estimator\n",
    "# filename = 'persistence/rfc_' + str(date.today()) + '.sav'\n",
    "# joblib.dump(rfc, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "==============\n",
      "Accuracy: 0.766057429283\n",
      "Precision: 0.782680061702\n",
      "Recall: 0.901598077295\n",
      "F1: 0.837940981871\n"
     ]
    }
   ],
   "source": [
    "#### Uncomment this cell to load trained Random Forest estimator from disk ####\n",
    "filename = 'persistence/rfc_2018-05-31.sav'\n",
    "rfc = joblib.load(filename)\n",
    "\n",
    "# Predict on eval set\n",
    "ypred_rfc = rfc.predict(Xeval)\n",
    "\n",
    "# Performance Metrics\n",
    "print('Random Forest')\n",
    "print('==============')\n",
    "print('Accuracy:',accuracy_score(yeval, ypred_rfc))\n",
    "print('Precision:',precision_score(yeval, ypred_rfc))\n",
    "print('Recall:', recall_score(yeval, ypred_rfc))\n",
    "print('F1:', f1_score(yeval, ypred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Uncomment this cell to train Naive Bayes estimator from scratch ####\n",
    "# # Build\n",
    "# gnb = GaussianNB()\n",
    "\n",
    "# # Train\n",
    "# start = time()\n",
    "# gnb.fit(Xtrain, ytrain)  \n",
    "# print('Training took ', time()-start, 'seconds.')\n",
    "\n",
    "# # Save the trained model \n",
    "# filename = 'persistence/gnb_'+ str(date.today()) + '.sav'\n",
    "# joblib.dump(gnb, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "==============\n",
      "Accuracy: 0.332396045051\n",
      "Precision: 0.767471410419\n",
      "Recall: 0.00687981957559\n",
      "F1: 0.01363738993\n"
     ]
    }
   ],
   "source": [
    "#### Uncomment this cell to load trained Naive Bayes estimator from disk ####\n",
    "filename = 'persistence/gnb_2018-05-31.sav'\n",
    "gnb = joblib.load(filename)\n",
    "\n",
    "# Predict on eval set\n",
    "ypred_gnb = gnb.predict(Xeval)\n",
    "\n",
    "# Performance Metrics\n",
    "print('Naive Bayes')\n",
    "print('==============')\n",
    "print('Accuracy:',accuracy_score(yeval, ypred_gnb))\n",
    "print('Precision:',precision_score(yeval, ypred_gnb))\n",
    "print('Recall:', recall_score(yeval, ypred_gnb))\n",
    "print('F1:', f1_score(yeval, ypred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest          0.766057\n",
       "Decision Tree          0.754886\n",
       "RBF-SVC                0.752029\n",
       "Logistic Regression    0.748231\n",
       "Linear SVC             0.745610\n",
       "Dummy Classifier       0.557796\n",
       "Naive Bayes            0.332396\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the best_score_ from each cross-validated algorithm in a series\n",
    "model_names = ['Dummy Classifier','Logistic Regression', 'Linear SVC', 'RBF-SVC', 'Decision Tree', 'Random Forest', 'Naive Bayes']\n",
    "model_scores = [accuracy_score(yeval, ypred_dummy), accuracy_score(yeval, ypred_logreg), accuracy_score(yeval, ypred_lsvc),\n",
    "                accuracy_score(yeval, ypred_svc29), accuracy_score(yeval, ypred_dtc), accuracy_score(yeval, ypred_rfc),\n",
    "                accuracy_score(yeval, ypred_gnb)]\n",
    "model_eval = pd.Series(data = model_scores, index = model_names).sort_values(ascending=False)\n",
    "model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best classifier, based on accuracy, is the Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6. Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict the Random Forest on the test data to see how well we can expect it to generalize to un-seen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting took  4.240575075149536 seconds.\n",
      "\n",
      "Random Forest\n",
      "====================\n",
      "Accuracy: 0.767916646609\n",
      "Precision: 0.785720221607\n",
      "Recall: 0.901125433852\n",
      "F1: 0.839475115332\n",
      "Confusion Matrix:\n",
      "[[ 30114  30942]\n",
      " [ 12449 113458]]\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.49      0.58     61056\n",
      "          1       0.79      0.90      0.84    125907\n",
      "\n",
      "avg / total       0.76      0.77      0.76    186963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "start = time()\n",
    "ypred_rfc_finaltest = rfc.predict(Xtest)\n",
    "print('Predicting took ', time()-start, 'seconds.')\n",
    "print('')\n",
    "\n",
    "# Performance Metrics\n",
    "print('Random Forest')\n",
    "print('====================')\n",
    "print('Accuracy:',accuracy_score(ytest, ypred_rfc_finaltest))\n",
    "print('Precision:',precision_score(ytest, ypred_rfc_finaltest))\n",
    "print('Recall:', recall_score(ytest, ypred_rfc_finaltest))\n",
    "print('F1:', f1_score(ytest, ypred_rfc_finaltest))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(ytest, ypred_rfc_finaltest))\n",
    "print('Classification Report:')\n",
    "print(classification_report(ytest, ypred_rfc_finaltest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the test metrics above, we can expect the random forest classifier to predict which citations will be paid with 77% accuracy. When it predicts a ticket will be paid, that ticket is in fact paid 79% of the time. Additionally, the random forest correctly anticipates 90% of all paid tickets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see which features of a citation are most important in determining whether it will be paid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Put the feature_importances_ in a dataframe\n",
    "imp_feats = pd.DataFrame({'features':np.array(X.columns), 'importance':rfc.feature_importances_})\n",
    "imp_feats.sort_values('importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>yr_2017</td>\n",
       "      <td>0.136559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>desc_FIXED SPEED CAMERA</td>\n",
       "      <td>0.075206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>yr_2016</td>\n",
       "      <td>0.070462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>mo_11</td>\n",
       "      <td>0.048725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fine</td>\n",
       "      <td>0.039258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>desc_EXPIRED TAGS</td>\n",
       "      <td>0.032805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>mo_9</td>\n",
       "      <td>0.029025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>quad_SOUTHEAST</td>\n",
       "      <td>0.024903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>desc_ALL OTHER PARKING METER VIOLATIONS</td>\n",
       "      <td>0.023458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instate</td>\n",
       "      <td>0.020739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    features  importance\n",
       "344                                  yr_2017    0.136559\n",
       "326                  desc_FIXED SPEED CAMERA    0.075206\n",
       "343                                  yr_2016    0.070462\n",
       "354                                    mo_11    0.048725\n",
       "0                                       fine    0.039258\n",
       "324                        desc_EXPIRED TAGS    0.032805\n",
       "352                                     mo_9    0.029025\n",
       "410                           quad_SOUTHEAST    0.024903\n",
       "318  desc_ALL OTHER PARKING METER VIOLATIONS    0.023458\n",
       "1                                    instate    0.020739"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_feats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features for determining whether a citation will be paid according to the random forest model are the: **year** of citation, the **type of violation** that occured, the **month** of citation, and the **fine**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
