{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Revenue from Parking Citations in Baltimore\n",
    "Capstone Project for Springboard Data Science Bootcamp\n",
    "\n",
    "Tamara Monge\n",
    "\n",
    "### Section 4: Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "# analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "from time import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# supervised learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score   \n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing all ones (all citations were paid) results in a  67.0 % success rate.\n",
      "Can models do better?\n"
     ]
    }
   ],
   "source": [
    "# Import prepared feature array\n",
    "X = pd.read_csv('persistence/features_2018-05-25.csv') #('persistence/features_2018-05-22.csv')\n",
    "X.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "# Import prepared target vector\n",
    "y = pd.read_csv('persistence/target_2018-05-22.csv', header=None).iloc[:,1]\n",
    "\n",
    "print('Guessing all ones (all citations were paid) results in a ', round(100*y.sum()/y.count()),'% success rate.')\n",
    "print('Can models do better?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's start with a dummy classifier that predicts using only the `fine` feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623208, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import prepared dummy feature array (contains only `fine`)\n",
    "F = pd.read_csv('persistence/fine_' + str(date.today()) + '.csv', header=None).iloc[:,1:2]\n",
    "F.shape\n",
    "\n",
    "# Scale it and split it\n",
    "Fscaled = scale(F)\n",
    "Ftrain, Ftest, ytrain, ytest = train_test_split(Fscaled, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71368666527601721"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build dummy classifier\n",
    "dummy = DecisionTreeClassifier() #LogisticRegression(C = 1)\n",
    "# Fit and test \n",
    "dummy.fit(Ftrain, ytrain).score(Ftest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the dummy classifier predicts with 71.4% accuracy, which is better than the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to more complex classifiers. We must first normalize the data and split it into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize/scale data\n",
    "Xscaled = scale(X)\n",
    "\n",
    "# Split data for training and testing 70%/30%\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xscaled, y, train_size=0.7, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took  1708.6171028614044 seconds.\n",
      "Best parameters: {'C': 1}\n",
      "Best score: 0.748036080643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['persistence/logreg_2018-05-25.sav']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Uncomment this section to train model from scratch ####\n",
    "# GridSearch Cross Validation to find best hyperparameters\n",
    "logreg_params = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "logreg = GridSearchCV(LogisticRegression(), logreg_params, cv=5, scoring=make_scorer(accuracy_score))\n",
    "start = time()\n",
    "logreg.fit(Xtrain, ytrain)  \n",
    "print('Training took ', time()-start, 'seconds.')\n",
    "print('Best parameters:',logreg.best_params_)\n",
    "print('Best score:', logreg.best_score_)\n",
    "\n",
    "# Save the trained model \n",
    "filename = 'persistence/logreg_' + str(date.today()) + '.sav'\n",
    "joblib.dump(logreg, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Load trained model from disk\n",
    "# filename = 'persistence/logreg_2018-05-13.sav'\n",
    "# logreg = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took  4203.443771839142 seconds.\n",
      "Best parameters: {'C': 0.01}\n",
      "Best score: 0.745615422526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['persistence/lsvc_2018-05-25.sav']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Uncomment this section to train model from scratch ####\n",
    "# GridSearch Cross Validation to find best hyperparameters\n",
    "lsvc_params =  {\"C\":[0.01, 0.1, 1, 10, 100]}\n",
    "lsvc = GridSearchCV(LinearSVC(), lsvc_params, n_jobs=4, cv=5, scoring=make_scorer(accuracy_score))\n",
    "start = time()\n",
    "lsvc.fit(Xtrain, ytrain)  \n",
    "print('Training took ', time()-start, 'seconds.')\n",
    "print('Best parameters:', lsvc.best_params_)\n",
    "print('Best score:', lsvc.best_score_)\n",
    "\n",
    "# Save the trained model \n",
    "filename = 'persistence/lsvc_'+ str(date.today()) + '.sav'\n",
    "joblib.dump(lsvc, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Load trained model from disk\n",
    "# filename = 'persistence/lsvc_2018-05-13.sav'\n",
    "# lsvc = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) SVC with RBF Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the RBF-SVC on the entire feature array is untennable (didn't finish in 14 days). \n",
    "To work around this, let's select a manageable number (20-30) of the most important features based on the coefficients returned from the logistic regression classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.595356</td>\n",
       "      <td>desc_ALL OTHER PARKING METER VIOLATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.422591</td>\n",
       "      <td>desc_NO STOPPING/STANDING NOT TOW-AWAY ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.368754</td>\n",
       "      <td>desc_NO STOPPING/STANDING TOW AWAY ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.368252</td>\n",
       "      <td>desc_RESIDENTIAL PARKING PERMIT ONLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.342040</td>\n",
       "      <td>desc_FIXED SPEED CAMERA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.317259</td>\n",
       "      <td>desc_NO STOP/PARK STREET CLEANING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.230306</td>\n",
       "      <td>desc_ALL OTHER STOPPING OR PARKING VIOLATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.214621</td>\n",
       "      <td>instate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.195964</td>\n",
       "      <td>desc_OBSTRUCT/IMPEDING MOVEMENT OF PEDESTRIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.187244</td>\n",
       "      <td>desc_IN TRANSIT ZONE/STOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.177881</td>\n",
       "      <td>desc_NO STOP/PARK HANDICAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.161437</td>\n",
       "      <td>quad_SOUTHEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.153554</td>\n",
       "      <td>desc_NO STOPPING//PARKING STADIUM EVENT CAMDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.148418</td>\n",
       "      <td>desc_PASSENGER LOADING ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.137461</td>\n",
       "      <td>desc_LESS THAN 15 FEET FROM FIRE HYDRANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.100978</td>\n",
       "      <td>make_TOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.080775</td>\n",
       "      <td>make_UPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.079539</td>\n",
       "      <td>desc_COMMERCIAL VEH/RESIDENCE UNDER 20,000 LBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.079439</td>\n",
       "      <td>make_SUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.068966</td>\n",
       "      <td>quad_SOUTHWEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.067927</td>\n",
       "      <td>desc_OBSTRUCT/IMPEDING FLOW OF TRAFFIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.061791</td>\n",
       "      <td>quad_NORTHWEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.043631</td>\n",
       "      <td>make_MAZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.042606</td>\n",
       "      <td>desc_EXCEEDING 48 HOURS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.041353</td>\n",
       "      <td>make_TRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.040289</td>\n",
       "      <td>desc_COMMERCIAL VEH/RESIDENCE OVER 20,000 LBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.038810</td>\n",
       "      <td>make_VPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.038310</td>\n",
       "      <td>desc_BLOCKING GARAGE OR DRIVEWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.036606</td>\n",
       "      <td>desc_FIRE LANE/HANDICAPPED VIOLATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.034337</td>\n",
       "      <td>desc_EXPIRED TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-0.029452</td>\n",
       "      <td>make_SAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>-0.031339</td>\n",
       "      <td>day_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.034280</td>\n",
       "      <td>mo_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>-0.034852</td>\n",
       "      <td>day_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>-0.038446</td>\n",
       "      <td>day_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-0.038823</td>\n",
       "      <td>make_INF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-0.041923</td>\n",
       "      <td>make_OLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>-0.043151</td>\n",
       "      <td>day_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-0.044140</td>\n",
       "      <td>make_LIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.044650</td>\n",
       "      <td>make_BUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-0.045873</td>\n",
       "      <td>make_PON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.047966</td>\n",
       "      <td>make_CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.048666</td>\n",
       "      <td>make_MER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.055370</td>\n",
       "      <td>mo_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.060736</td>\n",
       "      <td>make_DOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.067206</td>\n",
       "      <td>make_ACU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.071959</td>\n",
       "      <td>make_CHR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-0.098682</td>\n",
       "      <td>mo_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.125649</td>\n",
       "      <td>mo_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.152705</td>\n",
       "      <td>mo_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.161277</td>\n",
       "      <td>make_TRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.172743</td>\n",
       "      <td>fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.182879</td>\n",
       "      <td>mo_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-0.307531</td>\n",
       "      <td>mo_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.388127</td>\n",
       "      <td>mo_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.403356</td>\n",
       "      <td>yr_2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.417006</td>\n",
       "      <td>mo_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.422025</td>\n",
       "      <td>mo_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.626062</td>\n",
       "      <td>mo_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-1.099436</td>\n",
       "      <td>yr_2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficients                                        features\n",
       "318      0.595356         desc_ALL OTHER PARKING METER VIOLATIONS\n",
       "336      0.422591     desc_NO STOPPING/STANDING NOT TOW-AWAY ZONE\n",
       "337      0.368754         desc_NO STOPPING/STANDING TOW AWAY ZONE\n",
       "341      0.368252            desc_RESIDENTIAL PARKING PERMIT ONLY\n",
       "326      0.342040                         desc_FIXED SPEED CAMERA\n",
       "332      0.317259               desc_NO STOP/PARK STREET CLEANING\n",
       "319      0.230306   desc_ALL OTHER STOPPING OR PARKING VIOLATIONS\n",
       "1        0.214621                                         instate\n",
       "339      0.195964   desc_OBSTRUCT/IMPEDING MOVEMENT OF PEDESTRIAN\n",
       "328      0.187244                       desc_IN TRANSIT ZONE/STOP\n",
       "331      0.177881                      desc_NO STOP/PARK HANDICAP\n",
       "410      0.161437                                  quad_SOUTHEAST\n",
       "335      0.153554  desc_NO STOPPING//PARKING STADIUM EVENT CAMDEN\n",
       "340      0.148418                     desc_PASSENGER LOADING ZONE\n",
       "330      0.137461        desc_LESS THAN 15 FEET FROM FIRE HYDRANT\n",
       "280      0.100978                                        make_TOY\n",
       "293      0.080775                                        make_UPS\n",
       "322      0.079539  desc_COMMERCIAL VEH/RESIDENCE UNDER 20,000 LBS\n",
       "262      0.079439                                        make_SUB\n",
       "411      0.068966                                  quad_SOUTHWEST\n",
       "338      0.067927          desc_OBSTRUCT/IMPEDING FLOW OF TRAFFIC\n",
       "409      0.061791                                  quad_NORTHWEST\n",
       "178      0.043631                                        make_MAZ\n",
       "323      0.042606                         desc_EXCEEDING 48 HOURS\n",
       "284      0.041353                                        make_TRU\n",
       "321      0.040289   desc_COMMERCIAL VEH/RESIDENCE OVER 20,000 LBS\n",
       "306      0.038810                                        make_VPG\n",
       "320      0.038310                desc_BLOCKING GARAGE OR DRIVEWAY\n",
       "325      0.036606            desc_FIRE LANE/HANDICAPPED VIOLATION\n",
       "324      0.034337                               desc_EXPIRED TAGS\n",
       "..            ...                                             ...\n",
       "242     -0.029452                                        make_SAT\n",
       "378     -0.031339                                          day_24\n",
       "345     -0.034280                                            mo_2\n",
       "362     -0.034852                                           day_8\n",
       "385     -0.038446                                          day_31\n",
       "141     -0.038823                                        make_INF\n",
       "210     -0.041923                                        make_OLD\n",
       "384     -0.043151                                          day_30\n",
       "168     -0.044140                                        make_LIN\n",
       "55      -0.044650                                        make_BUI\n",
       "222     -0.045873                                        make_PON\n",
       "59      -0.047966                                        make_CAD\n",
       "187     -0.048666                                        make_MER\n",
       "346     -0.055370                                            mo_3\n",
       "87      -0.060736                                        make_DOD\n",
       "31      -0.067206                                        make_ACU\n",
       "68      -0.071959                                        make_CHR\n",
       "347     -0.098682                                            mo_4\n",
       "348     -0.125649                                            mo_5\n",
       "349     -0.152705                                            mo_6\n",
       "281     -0.161277                                        make_TRA\n",
       "0       -0.172743                                            fine\n",
       "350     -0.182879                                            mo_7\n",
       "355     -0.307531                                           mo_12\n",
       "351     -0.388127                                            mo_8\n",
       "343     -0.403356                                         yr_2016\n",
       "353     -0.417006                                           mo_10\n",
       "352     -0.422025                                            mo_9\n",
       "354     -0.626062                                           mo_11\n",
       "344     -1.099436                                         yr_2017\n",
       "\n",
       "[412 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the logreg    \n",
    "clf = LogisticRegression(C=1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Put the coefficients in a dataframe\n",
    "df_features = pd.DataFrame({'features':np.array(X.columns), 'coefficients':clf.coef_[0,:]})\n",
    "df_features.sort_values('coefficients', ascending=False)\n",
    "\n",
    "# Determine which threshold to use to get a manageable number of features (20-30)\n",
    "(abs(df_features.coefficients) >= 0.5).sum()\n",
    "(abs(df_features.coefficients) >= 0.2).sum()\n",
    "(abs(df_features.coefficients) >= 0.1).sum()\n",
    "(abs(df_features.coefficients) >= 0.07).sum()\n",
    "(abs(df_features.coefficients) >= 0.05).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like a threshold of >= 0.2 will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.172743</td>\n",
       "      <td>fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.214621</td>\n",
       "      <td>instate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.100978</td>\n",
       "      <td>make_TOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.161277</td>\n",
       "      <td>make_TRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.595356</td>\n",
       "      <td>desc_ALL OTHER PARKING METER VIOLATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.230306</td>\n",
       "      <td>desc_ALL OTHER STOPPING OR PARKING VIOLATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.342040</td>\n",
       "      <td>desc_FIXED SPEED CAMERA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.187244</td>\n",
       "      <td>desc_IN TRANSIT ZONE/STOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.137461</td>\n",
       "      <td>desc_LESS THAN 15 FEET FROM FIRE HYDRANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.177881</td>\n",
       "      <td>desc_NO STOP/PARK HANDICAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.317259</td>\n",
       "      <td>desc_NO STOP/PARK STREET CLEANING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.153554</td>\n",
       "      <td>desc_NO STOPPING//PARKING STADIUM EVENT CAMDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.422591</td>\n",
       "      <td>desc_NO STOPPING/STANDING NOT TOW-AWAY ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.368754</td>\n",
       "      <td>desc_NO STOPPING/STANDING TOW AWAY ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.195964</td>\n",
       "      <td>desc_OBSTRUCT/IMPEDING MOVEMENT OF PEDESTRIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.148418</td>\n",
       "      <td>desc_PASSENGER LOADING ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.368252</td>\n",
       "      <td>desc_RESIDENTIAL PARKING PERMIT ONLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.403356</td>\n",
       "      <td>yr_2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-1.099436</td>\n",
       "      <td>yr_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.125649</td>\n",
       "      <td>mo_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.152705</td>\n",
       "      <td>mo_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.182879</td>\n",
       "      <td>mo_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.388127</td>\n",
       "      <td>mo_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.422025</td>\n",
       "      <td>mo_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.417006</td>\n",
       "      <td>mo_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.626062</td>\n",
       "      <td>mo_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-0.307531</td>\n",
       "      <td>mo_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.161437</td>\n",
       "      <td>quad_SOUTHEAST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficients                                        features\n",
       "0       -0.172743                                            fine\n",
       "1        0.214621                                         instate\n",
       "280      0.100978                                        make_TOY\n",
       "281     -0.161277                                        make_TRA\n",
       "318      0.595356         desc_ALL OTHER PARKING METER VIOLATIONS\n",
       "319      0.230306   desc_ALL OTHER STOPPING OR PARKING VIOLATIONS\n",
       "326      0.342040                         desc_FIXED SPEED CAMERA\n",
       "328      0.187244                       desc_IN TRANSIT ZONE/STOP\n",
       "330      0.137461        desc_LESS THAN 15 FEET FROM FIRE HYDRANT\n",
       "331      0.177881                      desc_NO STOP/PARK HANDICAP\n",
       "332      0.317259               desc_NO STOP/PARK STREET CLEANING\n",
       "335      0.153554  desc_NO STOPPING//PARKING STADIUM EVENT CAMDEN\n",
       "336      0.422591     desc_NO STOPPING/STANDING NOT TOW-AWAY ZONE\n",
       "337      0.368754         desc_NO STOPPING/STANDING TOW AWAY ZONE\n",
       "339      0.195964   desc_OBSTRUCT/IMPEDING MOVEMENT OF PEDESTRIAN\n",
       "340      0.148418                     desc_PASSENGER LOADING ZONE\n",
       "341      0.368252            desc_RESIDENTIAL PARKING PERMIT ONLY\n",
       "343     -0.403356                                         yr_2016\n",
       "344     -1.099436                                         yr_2017\n",
       "348     -0.125649                                            mo_5\n",
       "349     -0.152705                                            mo_6\n",
       "350     -0.182879                                            mo_7\n",
       "351     -0.388127                                            mo_8\n",
       "352     -0.422025                                            mo_9\n",
       "353     -0.417006                                           mo_10\n",
       "354     -0.626062                                           mo_11\n",
       "355     -0.307531                                           mo_12\n",
       "410      0.161437                                  quad_SOUTHEAST"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(623208, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the top 28 features from LogReg #21\n",
    "df_select28 = df_features[abs(df_features.coefficients) >= 0.1] #>=0.2\n",
    "df_select28\n",
    "\n",
    "# Extract only the 28 identified features\n",
    "X28 = X[df_select28.features]\n",
    "X28.shape\n",
    "\n",
    "# Normalize/scale \n",
    "X28scaled = scale(X28)\n",
    "\n",
    "# Split data for training-testing 70%-30%\n",
    "X28train, X28test, y28train, y28test = train_test_split(X28scaled, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the pared-down feature array, let's train the svc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 100], 'gamma': [0.25, 0.5, 0.75]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227735.89946818352\n",
      "Training took  227735.89978194237 seconds.\n",
      "Best parameters: {'C': 1, 'gamma': 0.25}\n",
      "Best score: 0.752675675366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['persistence/svc28_2018-05-28.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Uncomment this section to train model from scratch ####\n",
    "# GridSearch Cross Validation to find best hyperparameters\n",
    "svc_params =  {\"C\":[0.01, 0.1, 1, 10, 100], \"gamma\":[0.25, 0.5, 0.75]}\n",
    "svc28 = GridSearchCV(SVC(), svc_params, n_jobs=4, cv=5, scoring=make_scorer(accuracy_score))\n",
    "start = time()\n",
    "svc28.fit(X28train, y28train)\n",
    "print(time()-start)\n",
    "print('Training took ', time()-start, 'seconds.')\n",
    "print('Best parameters:', svc28.best_params_)\n",
    "print('Best score:', svc28.best_score_)\n",
    "\n",
    "# Save the trained model \n",
    "filename = 'persistence/svc28_'+ str(date.today()) + '.sav'\n",
    "joblib.dump(svc28, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Load trained model from disk\n",
    "# filename = 'persistence/svc21_2018-05-17.sav'\n",
    "# svc21 = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  D) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'max_depth': [5, 10, 30, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took  273.9086368083954 seconds.\n",
      "Best parameters: {'max_depth': 10}\n",
      "Best score: 0.755270547513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['persistence/dtc_2018-05-25.sav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Uncomment this section to train model from scratch ####\n",
    "# GridSearch Cross Validation to find best hyperparameters\n",
    "dtc_params =  {\"max_depth\":[5, 10, 30, 50, 100]}\n",
    "dtc = GridSearchCV(DecisionTreeClassifier(), dtc_params, n_jobs=4, cv=5, scoring=make_scorer(accuracy_score))\n",
    "start = time()\n",
    "dtc.fit(Xtrain, ytrain)  \n",
    "print('Training took ', time()-start, 'seconds.')\n",
    "print('Best parameters:', dtc.best_params_)\n",
    "print('Best score:', dtc.best_score_)\n",
    "\n",
    "# Save the trained model \n",
    "filename = 'persistence/dtc_'+ str(date.today()) + '.sav'\n",
    "joblib.dump(dtc, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Load trained model from disk\n",
    "# filename = 'persistence/dtc_2018-05-20.sav'\n",
    "# dtc = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'max_depth': [5, 10, 30, 50, 100], 'n_estimators': [5, 10, 25, 50], 'min_samples_leaf': [1, 2, 4, 7, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took  6050.578860044479 seconds.\n",
      "Best parameters: {'max_depth': 100, 'min_samples_leaf': 2, 'n_estimators': 50}\n",
      "Best score: 0.766085571181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['persistence/rfc_2018-05-26.sav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Uncomment this section to train model from scratch ####\n",
    "# GridSearch Cross Validation to find best hyperparameters\n",
    "rfc_params =  {\"max_depth\":[5, 10, 30, 50, 100], \"n_estimators\":[5, 10, 25, 50], \"min_samples_leaf\":[1, 2, 4, 7, 10]}\n",
    "# (max_depth=10, n_estimators=10, max_features=100)\n",
    "rfc = GridSearchCV(RandomForestClassifier(random_state=42), rfc_params, n_jobs=4, cv=5, scoring=make_scorer(accuracy_score))\n",
    "start = time()\n",
    "rfc.fit(Xtrain, ytrain)  \n",
    "print('Training took ', time()-start, 'seconds.')\n",
    "print('Best parameters:', rfc.best_params_)\n",
    "print('Best score:', rfc.best_score_)\n",
    "\n",
    "# Save the trained model\n",
    "filename = 'persistence/rfc_'+ str(date.today()) + '.sav'\n",
    "joblib.dump(rfc, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Load trained model from disk\n",
    "# filename = 'persistence/rfc_2018-05-20.sav'\n",
    "# rfc = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took  3.030113935470581 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['persistence/gnb_2018-05-25.sav']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.32820932483967413"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Uncomment this section to train model from scratch ####\n",
    "# Fit the model\n",
    "gnb = GaussianNB()\n",
    "start = time()\n",
    "gnb.fit(Xtrain, ytrain)  \n",
    "print('Training took ', time()-start, 'seconds.')\n",
    "\n",
    "# Save the trained model \n",
    "filename = 'persistence/gnb_'+ str(date.today()) + '.sav'\n",
    "joblib.dump(gnb, filename)\n",
    "\n",
    "gnb.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Load trained model from disk\n",
    "# filename = 'persistence/gnb_2018-05-20.sav'\n",
    "# gnb = joblib.load(filename)\n",
    "# gnb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the best_score_ from each cross-validated algorithm in a series\n",
    "model_names = ['Dummy Classifier','Logistic Regression', 'Linear SVC', 'RBF-SVC', 'Decision Tree', 'Random Forest', 'Naive Bayes']\n",
    "model_scores = [dummy.fit(Ftrain, ytrain).score(Ftest, ytest), logreg.best_score_, lsvc.best_score_, svc28.best_score_, dtc.best_score_, rfc.best_score_, gnb.score(Xtest, ytest)]\n",
    "model_eval = pd.Series(data = model_scores, index = model_names).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest          0.766086\n",
       "Decision Tree          0.755271\n",
       "RBF-SVC                0.752676\n",
       "Logistic Regression    0.748036\n",
       "Linear SVC             0.745615\n",
       "Dummy Classifier       0.713687\n",
       "Naive Bayes            0.328209\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best classifier, based on accuracy, is the Random Forest. \n",
    "\n",
    "Now let's predict the Random Forest on the test data to see how well we can expect it to generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6. Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting took  2.728756904602051 seconds.\n",
      "\n",
      "Random Forest\n",
      "====================\n",
      "Accuracy: 0.769114744629\n",
      "Precision: 0.786472038335\n",
      "Recall: 0.902062633531\n",
      "F1: 0.840310891946\n",
      "Confusion Matrix:\n",
      "[[ 30220  30836]\n",
      " [ 12331 113576]]\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.49      0.58     61056\n",
      "          1       0.79      0.90      0.84    125907\n",
      "\n",
      "avg / total       0.76      0.77      0.76    186963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "start = time()\n",
    "ypred_rfc = rfc.predict(Xtest)\n",
    "print('Predicting took ', time()-start, 'seconds.')\n",
    "print('')\n",
    "\n",
    "# Performance Metrics\n",
    "print('Random Forest')\n",
    "print('====================')\n",
    "print('Accuracy:',accuracy_score(ytest, ypred_rfc))\n",
    "print('Precision:',precision_score(ytest, ypred_rfc))\n",
    "print('Recall:', recall_score(ytest, ypred_rfc))\n",
    "print('F1:', f1_score(ytest, ypred_rfc))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(ytest, ypred_rfc))\n",
    "print('Classification Report:')\n",
    "print(classification_report(ytest, ypred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the test metrics above, we can expect the random forest classifier to predict which citations will be paid with 76.8% accuracy. When it predicts a ticket will be paid, that ticket is in fact paid 78.6% of the time. Additionally, the random forest correctly anticipates 90.2% of all paid tickets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see which features of a citation are most important in determining whether it will be paid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Random Forest (can't use rfc from above because it has a gridsearch estimator wrapped around it)\n",
    "model = RandomForestClassifier(max_depth=50, n_estimators= 50, min_samples_leaf=2, random_state=42)\n",
    "\n",
    "# Train it\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Put the feature_importances_ in a dataframe\n",
    "imp_feats = pd.DataFrame({'features':np.array(X.columns), 'importance':model.feature_importances_})\n",
    "imp_feats.sort_values('importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>yr_2017</td>\n",
       "      <td>0.147952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>desc_FIXED SPEED CAMERA</td>\n",
       "      <td>0.074493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>yr_2016</td>\n",
       "      <td>0.070097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>mo_11</td>\n",
       "      <td>0.055478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fine</td>\n",
       "      <td>0.043222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>desc_ALL OTHER PARKING METER VIOLATIONS</td>\n",
       "      <td>0.031214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>desc_EXPIRED TAGS</td>\n",
       "      <td>0.030861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>mo_9</td>\n",
       "      <td>0.029730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>quad_SOUTHEAST</td>\n",
       "      <td>0.024190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>mo_8</td>\n",
       "      <td>0.021665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    features  importance\n",
       "344                                  yr_2017    0.147952\n",
       "326                  desc_FIXED SPEED CAMERA    0.074493\n",
       "343                                  yr_2016    0.070097\n",
       "354                                    mo_11    0.055478\n",
       "0                                       fine    0.043222\n",
       "318  desc_ALL OTHER PARKING METER VIOLATIONS    0.031214\n",
       "324                        desc_EXPIRED TAGS    0.030861\n",
       "352                                     mo_9    0.029730\n",
       "410                           quad_SOUTHEAST    0.024190\n",
       "351                                     mo_8    0.021665"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_feats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features for determining whether a citation will be paid according to the random forest model are the: **year** of citation, the **type of violation** that occured, the **month** of citation, and the **fine**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
